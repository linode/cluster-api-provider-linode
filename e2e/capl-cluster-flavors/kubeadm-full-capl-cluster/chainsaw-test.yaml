# yaml-language-server: $schema=https://raw.githubusercontent.com/kyverno/chainsaw/main/.schemas/json/test-chainsaw-v1alpha1.json
apiVersion: chainsaw.kyverno.io/v1alpha1
kind: Test
metadata:
  creationTimestamp: null
  name: kubeadm-full-capl-cluster
  # Labels to allow the test to be triggered based on selector flag
  labels:
    all:
    kubeadm-full:
    flavors:
spec:
  bindings:
    # Identifier for the E2E test run
    - name: run
      value: (join('-', ['e2e', 'kdmf-tst', env('GIT_REF')]))
    - name: cluster
      # Format the cluster name
      value: (trim((truncate(($run), `29`)), '-'))
  template: true
  steps:
    # Test for initial resources allocation
    - name: Testing all CAPI provider resources
      try:
        - assert:
            file: assert-capi-resources.yaml

    # Test for generating cluster using clusterctl
    - name: Generate cluster using clusterctl
      try:
        - script:
            env:
              - name: CLUSTER
                value: ($cluster)
              - name: NAMESPACE
                value: ($namespace)
              - name: CLUSTERCTL_CONFIG
                value: (env('CLUSTERCTL_CONFIG'))
              - name: SSE_KEY
                value: "jU$n@AXXf3xseNd&U9ko4J#3B84D6YR6"
              - name: KONNECTIVITY_AGENT_REPLICAS
                value: '1' # Here, 1 is set for testing purposes. Default is 3.
              - name: CLUSTER_AUTOSCALER_VERSION
                value: 'v1.29.4'
              - name: ETCD_BACKUP_SCHEDULE
                value: '* * * * *'
              - name: KUBERNETES_VERSION
                value: (env('KUBERNETES_VERSION') || 'v1.29.1')
            content: |
              set -e
              if [ -z "$SSE_KEY" ]; then
                echo "SSE_KEY not set" >&2
                exit 1
              else
                clusterctl generate cluster $CLUSTER -n $NAMESPACE \
                --flavor kubeadm-full --kubernetes-version ${KUBERNETES_VERSION} \
                --infrastructure local-linode:v0.0.0 \
                --control-plane-machine-count 1 --worker-machine-count 1 \
                --config ${CLUSTERCTL_CONFIG:=${HOME}/.cluster-api/clusterctl.yaml} > kubeadm-full-cluster.yaml
              fi
            check:
              ($error == null): true

    # Test for applying created yaml
    - name: Testing all available resources
      try:
        - apply:
            file: kubeadm-full-cluster.yaml
        - assert:
            file: assert-child-cluster-resources.yaml
      catch:
        - describe:
            apiVersion: infrastructure.cluster.x-k8s.io/v1alpha2
            kind: LinodeMachine
        - describe:
            apiVersion: cluster.x-k8s.io/v1beta1
            kind: Machine
        - describe:
            apiVersion: cluster.x-k8s.io/v1beta1
            kind: MachineDeployment
        - describe:
            apiVersion: controlplane.cluster.x-k8s.io/v1beta1
            kind: KubeadmControlPlane
        - describe:
            apiVersion: addons.cluster.x-k8s.io/v1alpha1
            kind: HelmReleaseProxy
        - describe:
            cluster: ($cluster)
            apiVersion: cluster.x-k8s.io/v1beta1
            kind: Cluster
            namespace: ($namespace)
        - describe:
            cluster: ($cluster)
            apiVersion: infrastructure.cluster.x-k8s.io/v1alpha2
            kind: LinodeCluster
            namespace: ($namespace)

    # Test to check if linodes are created
    - name: Testing to see if the Linodes are created
      try:
        - script:
            env:
              - name: TARGET_API
                value: api.linode.com
              - name: TARGET_API_VERSION
                value: v4beta
              - name: URI
                value: linode/instances
              - name: FILTER
                value: (to_string({"tags":($cluster)}))
            content: |
              set -e
              curl -s \
                -H "Authorization: Bearer $LINODE_TOKEN" \
                -H "X-Filter: $FILTER" \
                -H "Content-Type: application/json" \
                "https://$TARGET_API/$TARGET_API_VERSION/$URI"
            check:
              ($error): ~
              (json_parse($stdout)):
                results: 2

    # Get the KUBECONFIG of the child cluster for later use
    - name: Get child cluster kubeconfig
      try:
        - script:
            env:
              - name: CLUSTER
                value: ($cluster)
              - name: NAMESPACE
                value: ($namespace)
              - name: CLUSTERCTL_CONFIG
                value: (env('CLUSTERCTL_CONFIG'))
            content: |
              set -e
              clusterctl get kubeconfig $CLUSTER -n $NAMESPACE > kubeadm-full-cluster-kubeconfig.yaml
            check:
              ($error == null): true

    # Test child cluster deployments
    - clusters:
        kubeadm-full-cluster:
          kubeconfig: ./kubeadm-full-cluster-kubeconfig.yaml
      name: Testing child cluster deployments
      try:
        - assert:
            cluster: kubeadm-full-cluster
            file: assert-child-cluster-deployments.yaml
      catch:
        - describe:
            cluster: kubeadm-full-cluster
            apiVersion: apps/v1
            kind: Deployment
            namespace: kube-system

    # Test for child cluster DaemonSets
    - clusters:
        kubeadm-full-cluster:
          kubeconfig: ./kubeadm-full-cluster-kubeconfig.yaml
      name: Testing child cluster DaemonSets
      try:
        - assert:
            cluster: kubeadm-full-cluster
            file: assert-child-cluster-daemonsets.yaml
      catch:
        - describe:
            cluster: kubeadm-full-cluster
            apiVersion: apps/v1
            kind: DaemonSet
            namespace: kube-system

    # Test for child cluster StatefulSets
    - clusters:
        kubeadm-full-cluster:
          kubeconfig: ./kubeadm-full-cluster-kubeconfig.yaml
      name: Testing child cluster StatefulSets
      try:
        - assert:
            cluster: kubeadm-full-cluster
            file: assert-child-cluster-statefulsets.yaml
      catch:
        - describe:
            cluster: kubeadm-full-cluster
            apiVersion: apps/v1
            kind: StatefulSet
            namespace: kube-system

    # Test Konnectivity server and agent
    - clusters:
        kubeadm-full-cluster:
          kubeconfig: ./kubeadm-full-cluster-kubeconfig.yaml
      name: Testing konnectivity resources
      try:
        - assert:
            cluster: kubeadm-full-cluster
            file: assert-konnectivity-resources.yaml
      catch:
        - describe:
            cluster: kubeadm-full-cluster
            apiVersion: apps/v1
            kind: Deployment
            namespace: kube-system
        - describe:
            cluster: kubeadm-full-cluster
            apiVersion: apps/v1
            kind: DaemonSet
            namespace: kube-system

    # Test to check if konnectivity is working
    - name: Testing to check if logs are retrievable
      try:
        - script:
            content: |

              MAX_RETRIES=5
              RETRY_DELAY=30 # 30 seconds delay before retrying
              ATTEMPT=0
              
              # retry loop to check if logs are retrievable from a pod
              while [ $ATTEMPT -lt $MAX_RETRIES ]; do
                KUBECONFIG=./kubeadm-full-cluster-kubeconfig.yaml kubectl logs csi-linode-controller-0 -n kube-system

                if [ -z "$error" ]; then
                  break
                else
                  ATTEMPT=$((ATTEMPT + 1))
                  sleep $RETRY_DELAY
                fi
              done

            check:
              ($error == null): true

    # Test to check if disks are added to the etcd spec
    - name: Testing to check if disks are added to the spec
      try:
        - script:
            env:
              - name: TARGET_API
                value: api.linode.com
              - name:  TARGET_API_VERSION
                value: v4beta
              - name: URI
                value: linode/instances
              - name: FILTER
                value: (to_string({"tags":($cluster)}))
            content: |
              set -e

              MAX_RETRIES=5
              RETRY_DELAY=30 # 30 second delay before retrying
              ATTEMPT=0
              ETCD_LABEL=""
              ETCD_STATUS=""
              
              # retry loop to check if etcd disk is attached 
              while [ $ATTEMPT -lt $MAX_RETRIES ]; do
                
                # API call to get the linode ID
                RESPONSE=$(curl -s \
                  -H "Authorization: Bearer $LINODE_TOKEN" \
                  -H "X-Filter: $FILTER" \
                  -H "Content-Type: application/json" \
                  "https://$TARGET_API/$TARGET_API_VERSION/$URI")

                LINODE_ID=$(echo "$RESPONSE" | jq -r '.data[0].id')

                if [ -z "$LINODE_ID" ]; then
                  echo "Error: LINODE_ID is empty. Response was: $RESPONSE"
                  exit 1
                fi
                
                # API call to check the list of disks attached 
                DISK_RESPONSE=$(curl -s \
                  -H "Authorization: Bearer $LINODE_TOKEN" \
                  -H "Content-Type: application/json" \
                  "https://$TARGET_API/$TARGET_API_VERSION/$URI/$LINODE_ID/disks?page=1&page_size=100")

                ETCD_LABEL=$(echo "$DISK_RESPONSE" | jq -r '.data[2].label')
                ETCD_STATUS=$(echo "$DISK_RESPONSE" | jq -r '.data[2].status')
          
                if [ "$ETCD_LABEL" == "etcd_disk" ] && [ "$ETCD_STATUS" == "ready" ]; then
                  break
                else
                  ATTEMPT=$((ATTEMPT + 1))
                  sleep $RETRY_DELAY
                fi
              done

              echo "{
                \"label\": \"$ETCD_LABEL\",
                \"status\": \"$ETCD_STATUS\"
              }"

            check:
              ($error): ~
              (json_parse($stdout)):
                label: etcd_disk
                status: ready

    # Test to query the object storage bucket and check for data
    - name: Testing the object storage buckets
      try:
        - script:
            env:
              - name: TARGET_API
                value: api.linode.com
              - name: TARGET_API_VERSION
                value: v4beta
              - name: BUCKET_NAME
                value: (join('-', ['e2e', 'kdmf-tst', env('GIT_REF'), 'etcd-backup']))
              - name: URI
                value: (join('/', ['object-storage', 'buckets', env('LINODE_REGION')]))
            content: |
              set -e

              MAX_RETRIES=5
              RETRY_DELAY=40 # 40 second delay before retrying
              ATTEMPT=0
              VALID_BUCKET=false

              # retry loop to check if bucket is created and objects are present
              while [ $ATTEMPT -lt $MAX_RETRIES ]; do
                
                # API call to get the bucket details
                RESPONSE=$(curl -s \
                  -H "Authorization: Bearer $LINODE_TOKEN" \
                  -H "Content-Type: application/json" \
                  "https://$TARGET_API/$TARGET_API_VERSION/$URI/$BUCKET_NAME")

                BUCKET_SIZE=$(echo "$RESPONSE" | jq -r '.size')
                BUCKET_OBJECTS=$(echo "$RESPONSE" | jq -r '.objects')

                if [ "$BUCKET_SIZE" -gt 0 ] && [ "$BUCKET_OBJECTS" -gt 0 ]; then
                  VALID_BUCKET=true
                  break
                else
                  ATTEMPT=$((ATTEMPT + 1))
                  sleep $RETRY_DELAY
                fi
              done

              echo "{
                \"status\": \"$VALID_BUCKET\"
              }"

            check:
              ($error): ~
              (json_parse($stdout)):
                status: "true"

    # Test to check object storage buckets and delete it
    - name: Deleting object storage bucket
      try:
        - script:
            env:
              - name: CAPL_KUBECONFIG
                value: ./kubeadm-full-cluster-kubeconfig.yaml
              - name: BUCKET_NAME
                value: (join('-', ['e2e', 'kdmf-tst', env('GIT_REF'), 'etcd-backup']))
              - name: SECRET_NAME
                value: (join('-', ['e2e', 'kdmf-tst', env('GIT_REF'), 'etcd-backup-obj-key']))
              - name: BUCKET_ENDPOINT
                value: (join('.', [(join('-', [env('LINODE_REGION'), '1'])), 'linodeobjects', 'com' ]))
              - name: LOCAL_BIN
                value: (env('LOCALBIN'))
              - name: BUCKET_REGION
                value: env('LINODE_REGION')
              - name: TARGET_API
                value: api.linode.com
              - name: TARGET_API_VERSION
                value: v4beta
              - name: URI
                value: (join('/', ['object-storage', 'buckets', env('LINODE_REGION')]))
            content: |
              set -e
            
              # Getting the keys from the CAPL cluster
              access_key=$(KUBECONFIG=$CAPL_KUBECONFIG kubectl get secret $SECRET_NAME -n kube-system -o=jsonpath='{.data.access_key}' | base64 -d)
              secret_key=$(KUBECONFIG=$CAPL_KUBECONFIG kubectl get secret $SECRET_NAME -n kube-system -o=jsonpath='{.data.secret_key}' | base64 -d)

              #Storing the keys into a config file
              cat <<EOL > .s5cfg
              [default]
              aws_access_key_id=$access_key
              aws_secret_access_key=$secret_key
              aws_default_region=$BUCKET_REGION-1
              EOL
              
              # delete the objects
              $LOCAL_BIN/s5cmd --credentials-file .s5cfg --endpoint-url https://$BUCKET_ENDPOINT rm s3://$BUCKET_NAME/etcd-backup/v2/*
              
              # delete the bucket 
              curl --request DELETE \
                -H "Authorization: Bearer $LINODE_TOKEN" \
                -H "Content-Type: application/json" \
                "https://$TARGET_API/$TARGET_API_VERSION/$URI/$BUCKET_NAME"

            check:
              ($error): ~

    # Test to check if child cluster is deleted
    - name: Testing to see if child cluster is deleted
      try:
        - delete:
            ref:
              apiVersion: cluster.x-k8s.io/v1beta1
              kind: Cluster
              name: ($cluster)
        - delete:
            ref:
              apiVersion: infrastructure.cluster.x-k8s.io/v1alpha2
              kind: LinodeVPC
              name: ($cluster)
        - delete:
            ref:
              apiVersion: infrastructure.cluster.x-k8s.io/v1alpha2
              kind: LinodeFirewall
              name: ($cluster)
        - delete:
            ref:
              apiVersion: infrastructure.cluster.x-k8s.io/v1alpha2
              kind: LinodeFirewall
              name: ($cluster)-nb
        - error:
            file: check-child-cluster-vpc-and-firewall-deleted.yaml

    # Test to check if linodes are deleted
    - name: Testing to check if the linodes are deleted
      try:
        - script:
            env:
              - name: TARGET_API
                value: api.linode.com
              - name: TARGET_API_VERSION
                value: v4beta
              - name: URI
                value: linode/instances
              - name: FILTER
                value: (to_string({"tags":($cluster)}))
            content: |
              set -e
              curl -s \
                -H "Authorization: Bearer $LINODE_TOKEN" \
                -H "X-Filter: $FILTER" \
                -H "Content-Type: application/json" \
                "https://$TARGET_API/$TARGET_API_VERSION/$URI"
            check:
              ($error): ~
              (json_parse($stdout)):
                results: 0

    # Delete generated manifests
    - name: Delete generated child cluster manifest yaml
      try:
        - script:
            content: |
              rm -f kubeadm-full-cluster.yaml
              rm -f kubeadm-full-cluster-kubeconfig.yaml
              rm -f .s5cfg
            check:
              ($error == null): true
